{"cells":[{"cell_type":"code","source":["#creating SparkSession\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('TDSQL').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9176629-cd88-4335-9dec-6bd9b72531b0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#creating dataframe\ndf = spark.read.csv('/FileStore/tables/taxi_data.csv',inferSchema=True,header=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c924b7ee-5ed6-43c6-80d4-ba1d387aae71"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data=df.dropna()\ndata.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56d090c4-52bc-45b3-99ec-2c2dcdc01136"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[3]: 995134","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[3]: 995134"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["#Converted Date columns from StringType to timestamp \nfrom pyspark.sql.functions import *\n\nspark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"Legacy\")\ndata=data.withColumn('tpep_pickup_datetime',to_timestamp(data.tpep_pickup_datetime, 'MM/dd/yyyy HH:mm')).\\\n        withColumn('tpep_dropoff_datetime',to_timestamp(data.tpep_dropoff_datetime, 'MM/dd/yyyy HH:mm'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a2ae748e-1d77-4cb2-a4dc-5b07ed17b5ac"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pyspark.sql.functions as f\nfrom pyspark.sql.functions import *\n\n# Engineered features\n# Get rid of 27 categories into a dummy for condition. bad conditions include any of the categories below\n# Temperature should only make a difference when causes an inconvenience/discomfort\n# Get date, year, month, hour, day from tpep_pickup to perform analysis \n# Get trip duration and Covid\n\ndata = data.withColumn(\"good_condition\", when(f.col(\"condition\") == \"Snow\", 0) \\\n                        .when(f.col(\"condition\") == \"Rain / Windy\", 0) \\\n                        .when(f.col(\"condition\") == \"Heavy Rain\", 0) \\\n                        .when(f.col(\"condition\") == \"Rain\", 0) \\\n                        .when(f.col(\"condition\") == \"Heavy T-Storm\", 0) \\\n                        .when(f.col(\"condition\") == \"Thunder in the Vicinity\", 0) \\\n                        .when(f.col(\"condition\") == \"Thunder\", 0) \\\n                        .when(f.col(\"condition\") == \"Light Rain with Thunder\", 0) \\\n                        .when(f.col(\"condition\") == \"Thunder / Windy\", 0) \\\n                        .when(f.col(\"condition\") == \"T-Storm\", 0) \\\n                        .otherwise(1)) \\\n            .withColumn(\"extreme_temp\", when((f.col(\"temperature\") > 86) | (f.col(\"temperature\") < 21), 1).otherwise(0)) \\\n            .withColumn('date',to_date(data.tpep_pickup_datetime)) \\\n            .withColumn('year',year(data.tpep_pickup_datetime)) \\\n            .withColumn('month',month(data.tpep_pickup_datetime)) \\\n            .withColumn('hour', hour(data.tpep_pickup_datetime)) \\\n            .withColumn('day', dayofweek(data.tpep_pickup_datetime)) \\\n            .withColumn('trip_time', unix_timestamp(data.tpep_dropoff_datetime) - unix_timestamp(data.tpep_pickup_datetime)) \\\n            .withColumn('covid', when(f.col(\"tpep_pickup_datetime\") > \"2020-03-08 00:00:00\", 1).otherwise(0)) \n\ndata.show(1)   "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17719221-642f-45ba-a22a-691d3753ec0d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+----------+--------------+----------+---------+-------+------------+--------------+----------+--------------+----------+---------+-------+------------+--------------+-----------+-----------+--------+----------+--------+------+----------+--------------+------------+----------+----+-----+----+---+---------+-----+\n|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|ratecodeid|store_and_fwd_flag|pulocationid|dolocationid|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|borough_pu|median_rlst_pu|tourist_pu|entert_pu|park_pu|workplace_pu|residential_pu|borough_do|median_rlst_do|tourist_do|entert_do|park_do|workplace_do|residential_do|  rate_fare|temperature|humidity|wind speed|pressure|precip| condition|good_condition|extreme_temp|      date|year|month|hour|day|trip_time|covid|\n+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+----------+--------------+----------+---------+-------+------------+--------------+----------+--------------+----------+---------+-------+------------+--------------+-----------+-----------+--------+----------+--------+------+----------+--------------+------------+----------+----+-----+----+---+---------+-----+\n|       2| 2019-12-09 07:21:00|  2019-12-09 07:46:00|              1|         6.15|         1|                 N|         262|         244|           1|       23.5|  0.0|    0.5|       2.5|         0.0|                  0.3|        29.3|                 2.5| Manhattan|             0|         0|        1|      0|           0|             0| Manhattan|        603593|         0|        0|      0|           0|             1|3.821138211|         42|      89|        10|   30.16|   0.0|Light Rain|             1|           0|2019-12-09|2019|   12|   7|  2|     1500|    0|\n+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+----------+--------------+----------+---------+-------+------------+--------------+----------+--------------+----------+---------+-------+------------+--------------+-----------+-----------+--------+----------+--------+------+----------+--------------+------------+----------+----+-----+----+---+---------+-----+\nonly showing top 1 row\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+----------+--------------+----------+---------+-------+------------+--------------+----------+--------------+----------+---------+-------+------------+--------------+-----------+-----------+--------+----------+--------+------+----------+--------------+------------+----------+----+-----+----+---+---------+-----+\n|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|ratecodeid|store_and_fwd_flag|pulocationid|dolocationid|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|borough_pu|median_rlst_pu|tourist_pu|entert_pu|park_pu|workplace_pu|residential_pu|borough_do|median_rlst_do|tourist_do|entert_do|park_do|workplace_do|residential_do|  rate_fare|temperature|humidity|wind speed|pressure|precip| condition|good_condition|extreme_temp|      date|year|month|hour|day|trip_time|covid|\n+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+----------+--------------+----------+---------+-------+------------+--------------+----------+--------------+----------+---------+-------+------------+--------------+-----------+-----------+--------+----------+--------+------+----------+--------------+------------+----------+----+-----+----+---+---------+-----+\n|       2| 2019-12-09 07:21:00|  2019-12-09 07:46:00|              1|         6.15|         1|                 N|         262|         244|           1|       23.5|  0.0|    0.5|       2.5|         0.0|                  0.3|        29.3|                 2.5| Manhattan|             0|         0|        1|      0|           0|             0| Manhattan|        603593|         0|        0|      0|           0|             1|3.821138211|         42|      89|        10|   30.16|   0.0|Light Rain|             1|           0|2019-12-09|2019|   12|   7|  2|     1500|    0|\n+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+----------+--------------+----------+---------+-------+------------+--------------+----------+--------------+----------+---------+-------+------------+--------------+-----------+-----------+--------+----------+--------+------+----------+--------------+------------+----------+----+-----+----+---+---------+-----+\nonly showing top 1 row\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["df_tip = data.select(\"tip_amount\")\ndf_tip.summary().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87549227-b46f-4131-a725-a877705eb36b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+------------------+\n|summary|        tip_amount|\n+-------+------------------+\n|  count|            995134|\n|   mean| 3.048746259297771|\n| stddev|2.8264469154619736|\n|    min|               0.0|\n|    25%|              1.75|\n|    50%|              2.36|\n|    75%|              3.45|\n|    max|            411.38|\n+-------+------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+------------------+\n|summary|        tip_amount|\n+-------+------------------+\n|  count|            995134|\n|   mean| 3.048746259297771|\n| stddev|2.8264469154619736|\n|    min|               0.0|\n|    25%|              1.75|\n|    50%|              2.36|\n|    75%|              3.45|\n|    max|            411.38|\n+-------+------------------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# creating view from dataframe\ndata.createOrReplaceTempView(\"TD\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"327ff4f8-b428-4f51-94fd-16bffde7a664"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data_notip = spark.sql(\"select * from TD where tip_amount == 0\")\ndata_tip = spark.sql(\"select * from TD where tip_amount > 0 and tip_amount <= 6 limit 85000\")\ndata_hightip = spark.sql(\"select * from TD where tip_amount > 6 limit 83000\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddc24410-2fe9-443e-9bfb-9fe62fde386e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data= data_notip.union(data_tip).union(data_hightip) \ndata.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b1e6977-6bda-42e9-815c-35248c90c989"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[9]: 206327","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[9]: 206327"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["import pyspark.sql.functions as f\nfrom pyspark.sql.functions import *\n\ndata = data.withColumn('tip',when((f.col(\"tip_amount\") > 6) , 2).when((f.col(\"tip_amount\") == 0) , 0).otherwise(1)) \n\ndata.groupBy('tip').count().show()           "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c00a9ed-db4f-467d-b27f-e94c72757751"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-----+\n|tip|count|\n+---+-----+\n|  0|38327|\n|  1|85000|\n|  2|83000|\n+---+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-----+\n|tip|count|\n+---+-----+\n|  0|38327|\n|  1|85000|\n|  2|83000|\n+---+-----+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Create a 70-30 train test split\n\ntrain_data,test_data=data.randomSplit([0.7,0.3])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4b494ed6-b2e7-4a87-8903-5dc6ca49a482"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Import the required libraries\n\nfrom pyspark.ml.feature import VectorAssembler,StringIndexer\nfrom pyspark.ml import Pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c17c6e6-ce69-4381-a76f-45e4d13c6f55"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Use StringIndexer to convert the categorical columns to hold numerical data\n\nborough_pu_indexer = StringIndexer(inputCol='borough_pu',outputCol='borough_pu_index',handleInvalid='keep')\nborough_do_indexer = StringIndexer(inputCol='borough_do',outputCol='borough_do_index',handleInvalid='keep')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d9dcd44b-cd30-4b3f-ba5b-5217a2d55a50"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["assembler = VectorAssembler(inputCols=['fare_amount','passenger_count','borough_pu_index','borough_do_index','tourist_pu','entert_pu','workplace_pu','residential_pu','tourist_do','entert_do','workplace_do','residential_do','covid','good_condition','extreme_temp','hour','month'],outputCol=\"features\")   "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f11d3ef-55fe-4151-b169-032c306af2c9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Logistic Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"267c4197-cd52-456c-933e-0e3487a6d0a8"}}},{"cell_type":"code","source":["# Create an object for the Logistic Regression model\nfrom pyspark.ml.classification import LogisticRegression\nlr_model = LogisticRegression(labelCol='tip')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b61fb654-840d-4378-b970-ef8ed360a1cd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Pipeline is used to pass the data through indexer and assembler simultaneously.\n\npipe = Pipeline(stages=[borough_pu_indexer,borough_do_indexer,assembler]) \nfitted_pipe=pipe.fit(train_data)\ntrain_data=fitted_pipe.transform(train_data)\n\n# Fit the model on the train data\n\nfit_model = lr_model.fit(train_data.select(['features','tip']))\n\n# Transform the test data using the model to predict the duration\n\ntest_data=fitted_pipe.transform(test_data)\n\n# Store the results in a dataframe\n\nresults = fit_model.transform(test_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"266229c7-e49a-4810-bca6-52923445b4f8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Evaluation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71e13d68-aaab-48f8-acf6-be138e8306bd"}}},{"cell_type":"markdown","source":["##### Accuracy"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0abbf98c-ff31-4097-a8de-58da4391f1fd"}}},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nACC_evaluator = MulticlassClassificationEvaluator(labelCol=\"tip\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = ACC_evaluator.evaluate(results)\nprint(\"The accuracy of the model is {}\".format(accuracy))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd689607-70ce-48cf-a87b-16545e2411d5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"The accuracy of the model is 0.7725469880688349\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["The accuracy of the model is 0.7725469880688349\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["###### The Accuracy is 77% indicating that the models classification is really on the better side"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"065bb901-5104-4369-b9b5-c46fdcf8b8b4"}}},{"cell_type":"markdown","source":["##### F1 Score"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e30ac2f6-717a-40d4-8c1e-eb65982c6e4f"}}},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nACC_evaluator = MulticlassClassificationEvaluator(labelCol=\"tip\", predictionCol=\"prediction\", metricName=\"f1\")\nf1 = ACC_evaluator.evaluate(results)\nprint(\"The f1 of the model is {}\".format(f1))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70a58b0c-fe00-481d-b26a-e447d511ffc2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"The f1 of the model is 0.7310230423927568\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["The f1 of the model is 0.7310230423927568\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["##### Confusion matrix"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55495194-5125-4531-b76b-e1fd20c8fd75"}}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n\ny_true = results.select(\"tip\")\ny_true = y_true.toPandas()\n\ny_pred = results.select(\"prediction\")\ny_pred = y_pred.toPandas()\n\ncnf_matrix = confusion_matrix(y_true, y_pred)\nprint(\"Below is the confusion matrix \\n {}\".format(cnf_matrix))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f66e2384-e40b-4a21-a67a-9ed9299c9290"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Below is the confusion matrix \n [[ 1571  7784  2158]\n [  820 23404  1194]\n [  599  1495 22746]]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Below is the confusion matrix \n [[ 1571  7784  2158]\n [  820 23404  1194]\n [  599  1495 22746]]\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["###### The confusion matrix shows that the model classifies well"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e978c53-f249-4466-b11a-2bdfda982789"}}},{"cell_type":"markdown","source":["### NaiveBayes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"147a2990-f616-42bd-8f6f-a04c8029a7b5"}}},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nmulticlass_models = [('Naive Bayes', NaiveBayes(labelCol='tip'))]\n\nfor name, model in multiclass_models:\n\n    # Fit the model on the train data\n    fit_model = model.fit(train_data.select(['features','tip']))\n    \n    # Transform the test data using the model to predict the duration\n    results = fit_model.transform(test_data)\n\n    #evaluation matrix of all multi class models\n    ACC_evaluator = MulticlassClassificationEvaluator(labelCol=\"tip\", predictionCol=\"prediction\", metricName=\"accuracy\")\n    accuracy = ACC_evaluator.evaluate(results)\n      \n    ACC_evaluator2 = MulticlassClassificationEvaluator(labelCol=\"tip\", predictionCol=\"prediction\", metricName=\"f1\")\n    f1 = ACC_evaluator2.evaluate(results)\n         \n    print(name, accuracy, f1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3e040f7-ada2-4a4c-bb2f-57c1aeaa053f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Naive Bayes 0.717019313269981 0.697220909827838\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Naive Bayes 0.717019313269981 0.697220909827838\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Decision Tree and Random Forest"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4811e858-e8f1-4037-90b6-c4ca2609d780"}}},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier,NaiveBayes\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nmulticlass_models = [ ('Decision Tree',DecisionTreeClassifier(labelCol='tip')),('Random Forest Classifier', RandomForestClassifier(labelCol='tip'))]\n\n#pipe = Pipeline(stages=[borough_pu_indexer,borough_do_indexer,assembler])  \n#fitted_pipe=pipe.fit(train_data)\n#train_data=fitted_pipe.transform(train_data)\n#test_data=fitted_pipe.transform(test_data)\n\nfor name, model in multiclass_models:\n\n    # Fit the model on the train data\n    fit_model = model.fit(train_data.select(['features','tip']))\n    \n    # Transform the test data using the model to predict the duration\n    results = fit_model.transform(test_data)\n\n    #evaluation matrix of all multi class models\n    ACC_evaluator = MulticlassClassificationEvaluator(labelCol=\"tip\", predictionCol=\"prediction\", metricName=\"accuracy\")\n    accuracy = ACC_evaluator.evaluate(results)\n      \n    ACC_evaluator2 = MulticlassClassificationEvaluator(labelCol=\"tip\", predictionCol=\"prediction\", metricName=\"f1\")\n    f1 = ACC_evaluator2.evaluate(results)\n         \n    print(name, accuracy, f1)\n    print(fit_model.featureImportances)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b0d4d51-c7f2-4398-a081-756d0f31372c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Decision Tree 0.780333813601852 0.731456399365243\n(17,[0,2,3,4,7,11,15],[0.9470337153946539,0.008105608491462992,0.005260937750786267,0.0012352366301691263,0.031244356120595076,0.006917546066785768,0.00020259954554681446])\nRandom Forest Classifier 0.7809813666607308 0.7300980990886989\n(17,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],[0.5868186657285427,2.4997964103162824e-05,0.1666798950525914,0.09116858238010794,0.06629962046474405,0.009627029847371522,6.264963030325675e-06,0.018749383193863742,0.017837908157075814,0.02741953609994508,0.00010566999344310231,0.012649474892019173,0.00017847320414142751,8.653818763357875e-06,5.308225240151958e-06,0.002168076766384458,0.0002524592486324438])\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Decision Tree 0.780333813601852 0.731456399365243\n(17,[0,2,3,4,7,11,15],[0.9470337153946539,0.008105608491462992,0.005260937750786267,0.0012352366301691263,0.031244356120595076,0.006917546066785768,0.00020259954554681446])\nRandom Forest Classifier 0.7809813666607308 0.7300980990886989\n(17,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],[0.5868186657285427,2.4997964103162824e-05,0.1666798950525914,0.09116858238010794,0.06629962046474405,0.009627029847371522,6.264963030325675e-06,0.018749383193863742,0.017837908157075814,0.02741953609994508,0.00010566999344310231,0.012649474892019173,0.00017847320414142751,8.653818763357875e-06,5.308225240151958e-06,0.002168076766384458,0.0002524592486324438])\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["######  Feature Importances : fare_amount, borough_pu, tourist_pu, residential_pu, borough_do, residential_do, tourist_do, entert_do, hour"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a833641b-967a-493b-a7a2-6ad33327a334"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Taxi_Tip_MultiClass_Classification_Submit","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1726101925107051}},"nbformat":4,"nbformat_minor":0}
